# ğŸ§  LangAgent â€” LangChain + Ollama + Chroma RAG with Tools

A modular project demonstrating:

- Retrieval-Augmented Generation (RAG) with metadata
- Local LLM integration using **Ollama + LLaMA 3 (free)**
- Custom agent tool (like getting system time)
- Modular LangChain components: prompts, chains, chat models

---

## ğŸš€ Features

- ğŸ“„ Load and chunk documents
- ğŸ” Embed documents using `sentence-transformers`
- ğŸ§  Store/retrieve embeddings via **ChromaDB**
- ğŸ§  Use **local LLaMA 3 via Ollama** as the LLM
- ğŸ› ï¸ Tool-powered LangChain Agent (e.g., current system time)

---

## ğŸ—‚ï¸ Project Structure
lang-agent/
â”œâ”€â”€ 1_chat_models/                # Example scripts using LLM chat models
â”‚   â””â”€â”€ chat_model_example.py
â”‚
â”œâ”€â”€ 2_prompt_templates/           # Prompt examples
â”‚   â”œâ”€â”€ prompt_template_1.txt
â”‚   
â”‚
â”œâ”€â”€ 3_chains/                     # Chains combining LLM + tools
â”‚   â””â”€â”€ chain_example.py
â”‚
â”œâ”€â”€ 4_Rags/                       # Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ documents/                # Source text files
â”‚   â”‚   â”œâ”€â”€ dracula.txt
â”‚   â”‚   â””â”€â”€ lord_of_the_rings.txt
â”‚   â”œâ”€â”€ 1a_basic_part_1.py        # Embedding and saving Chroma vectorstore
â”‚   â”œâ”€â”€ 2a_rag_basics_metadata.py # Adding source metadata per document
â”‚   â””â”€â”€ 3_rag_query_llm.py        # Query vectorstore using Ollama
â”‚
â”œâ”€â”€ 5_agents/                     # LangChain Agent with tools
â”‚   â””â”€â”€ 1_agent_time_tool.py      # â€œGet timeâ€ tool using custom @tool
â”‚
â”œâ”€â”€ db/                           # Persistent ChromaDB vectorstore
â”‚   â””â”€â”€ chroma_db_with_metadata/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---

## ğŸ› ï¸ Setup Instructions

### 1. Install Ollama

You must have Ollama installed with LLaMA 3 pulled:

```bash
# Install Ollama (macOS/Linux/Windows WSL)
https://ollama.com/download

# Pull the free LLaMA 3 model
ollama pull llama3
2. Set up virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
ğŸ“¦ Requirements

Install dependencies:
pip install -r requirements.txt
Example requirements.txt:
langchain
langchain-community
langchain-core
langchainhub
langchain-chroma
sentence-transformers
chromadb
ollama
python-dotenv
ğŸ§  We use sentence-transformers for local embeddings (instead of OpenAI). No API keys needed.
ğŸ“„ Usage Examples

Embed Documents (1a & 2a)
cd 4_Rags
python 1a_basic_part_1.py
# or for metadata support:
python 2a_rag_basics_metadata.py
Query using Ollama LLaMA 3
python 3_rag_query_llm.py
Use Agent with Tool
cd 5_agents
python 1_agent_time_tool.py

ğŸ’¡ Tips
	â€¢	Store documents inside 4_Rags/documents/
	â€¢	Embeddings are saved in db/chroma_db_with_metadata/
	â€¢	Make sure Ollama is running in the background before querying the LLM

ğŸ“Œ Notes
	â€¢	âœ… Uses free local models â€” No API key required.
	â€¢	âœ… Fast prototyping with LangChain
	â€¢	âœ… Modular structure for extending with more tools or chains

ğŸ™Œ Acknowledgements
	â€¢	LangChain
	â€¢	Ollama
	â€¢	ChromaDB
	â€¢	Meta LLaMA 3

ğŸ“« Author

Vibha N R
Junior | AI & ML @ New Horizon College of Engineering
GitHub